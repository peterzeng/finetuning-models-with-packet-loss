{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a43b28e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30af88f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnli_gpt_dir = '/data01/pegah/finetuning-models-with-packet-loss/gpt2-large_output/mnli'\n",
    "# mnli_gpt_dir = '/data01/pegah/finetuning-models-with-packet-loss/output/mnli'\n",
    "# ge_gpt_dir = '/data01/pegah/finetuning-models-with-packet-loss/ge_gpt2-large_output/mnli'\n",
    "# ge_llama_dir = '/home/zengpe/dev/finetuning-models-with-packet-loss/ge_llama-3.2-1b_output/mnli'\n",
    "llama_dir = '/data01/pegah/finetuning-models-with-packet-loss/llama_output/mnli'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e80d21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7fbae206",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs = [\"0.0\", \"0.001\", \"0.002\", \"0.005\", \"0.01\"]\n",
    "# lrs = [\"0.002\"]\n",
    "# lrs = [\"one_percent\", \"half_percent\", \"point2_percent\", \"long_point1_percent\"]\n",
    "# lrs.extend([\"short_1percent\", \"short_half_percent\", \"short_point_2percent\", \"short_point1_percent\"])\n",
    "# lrs = [\"long_point1_percent\"]\n",
    "nodes = [\"2\", \"4\", \"8\", \"10\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69eccef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[120, 120, 140, 120, 120]\n",
      "lr: 0.0, nodes: 2, mean: 124.0, std: 8.0\n",
      "[80, 80, 100, 60, 80]\n",
      "lr: 0.0, nodes: 4, mean: 80.0, std: 12.649110640673518\n",
      "[60, 60, 80, 40, 60]\n",
      "lr: 0.0, nodes: 8, mean: 60.0, std: 12.649110640673518\n",
      "[40, 40, 40, 40, 40]\n",
      "lr: 0.0, nodes: 10, mean: 40.0, std: 0.0\n",
      "[120, 140, 120, 140, 120]\n",
      "lr: 0.001, nodes: 2, mean: 128.0, std: 9.797958971132712\n",
      "[80, 80, 80, 60, 60]\n",
      "lr: 0.001, nodes: 4, mean: 72.0, std: 9.797958971132712\n",
      "[80, 40, 40, 60, 60]\n",
      "lr: 0.001, nodes: 8, mean: 56.0, std: 14.966629547095765\n",
      "[40, 40, 40, 40, 60]\n",
      "lr: 0.001, nodes: 10, mean: 44.0, std: 8.0\n",
      "/data01/pegah/finetuning-models-with-packet-loss/llama_output/mnli/llama_2nodes_mnli_lr0.002_seed10/ttac_report.txt\n",
      "/data01/pegah/finetuning-models-with-packet-loss/llama_output/mnli/llama_2nodes_mnli_lr0.002_seed20/ttac_report.txt\n",
      "/data01/pegah/finetuning-models-with-packet-loss/llama_output/mnli/llama_2nodes_mnli_lr0.002_seed30/ttac_report.txt\n",
      "/data01/pegah/finetuning-models-with-packet-loss/llama_output/mnli/llama_2nodes_mnli_lr0.002_seed40/ttac_report.txt\n",
      "/data01/pegah/finetuning-models-with-packet-loss/llama_output/mnli/llama_2nodes_mnli_lr0.002_seed50/ttac_report.txt\n",
      "[]\n",
      "[100, 80, 100, 100, 80]\n",
      "lr: 0.002, nodes: 4, mean: 92.0, std: 9.797958971132712\n",
      "[80, 80, 80, 60, 60]\n",
      "lr: 0.002, nodes: 8, mean: 72.0, std: 9.797958971132712\n",
      "[40, 60, 60, 40, 60]\n",
      "lr: 0.002, nodes: 10, mean: 52.0, std: 9.797958971132712\n",
      "[120, 120, 120, 120, 120]\n",
      "lr: 0.005, nodes: 2, mean: 120.0, std: 0.0\n",
      "[120, 60, 140, 120, 100]\n",
      "lr: 0.005, nodes: 4, mean: 108.0, std: 27.129319932501073\n",
      "[80, 80, 80, 80, 100]\n",
      "lr: 0.005, nodes: 8, mean: 84.0, std: 8.0\n",
      "/data01/pegah/finetuning-models-with-packet-loss/llama_output/mnli/llama_10nodes_mnli_lr0.005_seed40/ttac_report.txt\n",
      "/data01/pegah/finetuning-models-with-packet-loss/llama_output/mnli/llama_10nodes_mnli_lr0.005_seed50/ttac_report.txt\n",
      "[60, 60, 60]\n",
      "lr: 0.005, nodes: 10, mean: 60.0, std: 0.0\n",
      "[120, 120, 140, 120, 200]\n",
      "lr: 0.01, nodes: 2, mean: 140.0, std: 30.983866769659336\n",
      "/data01/pegah/finetuning-models-with-packet-loss/llama_output/mnli/llama_4nodes_mnli_lr0.01_seed10/ttac_report.txt\n",
      "/data01/pegah/finetuning-models-with-packet-loss/llama_output/mnli/llama_4nodes_mnli_lr0.01_seed20/ttac_report.txt\n",
      "/data01/pegah/finetuning-models-with-packet-loss/llama_output/mnli/llama_4nodes_mnli_lr0.01_seed30/ttac_report.txt\n",
      "/data01/pegah/finetuning-models-with-packet-loss/llama_output/mnli/llama_4nodes_mnli_lr0.01_seed40/ttac_report.txt\n",
      "/data01/pegah/finetuning-models-with-packet-loss/llama_output/mnli/llama_4nodes_mnli_lr0.01_seed50/ttac_report.txt\n",
      "[]\n",
      "/data01/pegah/finetuning-models-with-packet-loss/llama_output/mnli/llama_8nodes_mnli_lr0.01_seed10/ttac_report.txt\n",
      "/data01/pegah/finetuning-models-with-packet-loss/llama_output/mnli/llama_8nodes_mnli_lr0.01_seed20/ttac_report.txt\n",
      "/data01/pegah/finetuning-models-with-packet-loss/llama_output/mnli/llama_8nodes_mnli_lr0.01_seed30/ttac_report.txt\n",
      "/data01/pegah/finetuning-models-with-packet-loss/llama_output/mnli/llama_8nodes_mnli_lr0.01_seed40/ttac_report.txt\n",
      "/data01/pegah/finetuning-models-with-packet-loss/llama_output/mnli/llama_8nodes_mnli_lr0.01_seed50/ttac_report.txt\n",
      "[]\n",
      "/data01/pegah/finetuning-models-with-packet-loss/llama_output/mnli/llama_10nodes_mnli_lr0.01_seed10/ttac_report.txt\n",
      "/data01/pegah/finetuning-models-with-packet-loss/llama_output/mnli/llama_10nodes_mnli_lr0.01_seed20/ttac_report.txt\n",
      "/data01/pegah/finetuning-models-with-packet-loss/llama_output/mnli/llama_10nodes_mnli_lr0.01_seed30/ttac_report.txt\n",
      "/data01/pegah/finetuning-models-with-packet-loss/llama_output/mnli/llama_10nodes_mnli_lr0.01_seed40/ttac_report.txt\n",
      "/data01/pegah/finetuning-models-with-packet-loss/llama_output/mnli/llama_10nodes_mnli_lr0.01_seed50/ttac_report.txt\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "for lr in lrs:\n",
    "    for node in nodes:\n",
    "        results = []\n",
    "        for seed in [10, 20, 30, 40, 50]:\n",
    "            # file_path = f\"\"\"{mnli_gpt_dir}/gpt2-large_{node}nodes_mnli_lr{lr}_seed{seed}/ttac_report.txt\"\"\"\n",
    "            # file_path = f\"\"\"{mnli_gpt_dir}/{node}nodes_mnli_lr{lr}_seed{seed}/ttac_report.txt\"\"\"\n",
    "            # file_path = f\"\"\"{ge_gpt_dir}/ge_gpt2-large_{node}nodes_mnli_lr_{lr}_seed{seed}/ttac_report.txt\"\"\"\n",
    "            # file_path = f\"\"\"{ge_llama_dir}/ge_llama-3.2-1b_{node}nodes_mnli_lr_{lr}_seed{seed}/ttac_report.txt\"\"\"\n",
    "            file_path=f\"{llama_dir}/llama_{node}nodes_mnli_lr{lr}_seed{seed}/ttac_report.txt\"\n",
    "            try:\n",
    "                \n",
    "                with open(file_path, 'r') as f:\n",
    "                    line = f.readlines()[0]\n",
    "                    step = int(line.split(' ')[-1])\n",
    "                    results.append(step)\n",
    "            except:\n",
    "                print(file_path)\n",
    "                continue\n",
    "        print(results)\n",
    "        if len(results) ==0:\n",
    "            continue\n",
    "        results = np.array(results)\n",
    "        mean = np.mean(results)\n",
    "        std = np.std(results)\n",
    "        print(f\"lr: {lr}, nodes: {node}, mean: {mean}, std: {std}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2c5ac4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2af032c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/palipoormola/miniconda3/envs/ajay/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9f85e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = AutoModelForCausalLM.from_pretrained('Qwen/Qwen2.5-1.5B-Instruct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b21b2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ajay",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
